{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combining BGE-M3's Signals\n",
    "\n",
    "Experiments from the blog post. Testing hybrid scoring with weights [0.4, 0.2, 0.4].\n",
    "\n",
    "**Data source:** [SemanticSonarDB](https://github.com/MrJoeSack/sqlserver-sample-databases/tree/master/semantic-sonar-db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run once)\n",
    "# pip install FlagEmbedding pyodbc numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pyodbc\n",
    "from FlagEmbedding import BGEM3FlagModel\n",
    "\n",
    "def get_conn():\n",
    "    return pyodbc.connect(\n",
    "        \"DRIVER={ODBC Driver 18 for SQL Server};\"\n",
    "        \"SERVER=localhost;DATABASE=SemanticSonarDB;\"\n",
    "        \"TrustServerCertificate=yes;Trusted_Connection=yes;\"\n",
    "    )\n",
    "\n",
    "print(\"Loading BGE-M3...\")\n",
    "model = BGEM3FlagModel('BAAI/bge-m3', use_fp16=False)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load sample documents\nconn = get_conn()\ncursor = conn.cursor()\ncursor.execute(\"\"\"\n    SELECT TOP 500 property_id, listing_description\n    FROM PropertyListings\n    WHERE listing_description IS NOT NULL\n    ORDER BY property_id\n\"\"\")\ndocs = [(r[0], r[1]) for r in cursor.fetchall()]\nconn.close()\n\nprint(f\"Loaded {len(docs)} documents\")"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode all documents with all three modes\n",
    "print(\"Encoding...\")\n",
    "doc_output = model.encode(\n",
    "    [d[1] for d in docs],\n",
    "    return_dense=True,\n",
    "    return_sparse=True,\n",
    "    return_colbert_vecs=True\n",
    ")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scoring functions\n",
    "\n",
    "def dense_score(q_emb, d_emb):\n",
    "    return float(q_emb @ d_emb.T)\n",
    "\n",
    "def sparse_score(q_sparse, d_sparse):\n",
    "    score = 0.0\n",
    "    for token in q_sparse:\n",
    "        if token in d_sparse:\n",
    "            score += min(q_sparse[token], d_sparse[token])\n",
    "    return score\n",
    "\n",
    "def colbert_score(q_vecs, d_vecs):\n",
    "    return model.colbert_score(q_vecs, d_vecs)\n",
    "\n",
    "def hybrid_score(dense, sparse, colbert, weights=(0.4, 0.2, 0.4)):\n",
    "    \"\"\"Paper recommends [0.4, 0.2, 0.4] for dense, sparse, colbert\"\"\"\n",
    "    return weights[0] * dense + weights[1] * sparse + weights[2] * colbert"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Finding Hybrid Discoveries\n",
    "\n",
    "Documents that hybrid ranks highly but no single mode puts in top 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_query(query, top_n=5):\n",
    "    \"\"\"Rank documents by all modes, return discoveries.\"\"\"\n",
    "    q_out = model.encode(\n",
    "        [query],\n",
    "        return_dense=True,\n",
    "        return_sparse=True,\n",
    "        return_colbert_vecs=True\n",
    "    )\n",
    "    \n",
    "    # Collect all scores\n",
    "    all_scores = []\n",
    "    for i, (pid, text) in enumerate(docs):\n",
    "        d = dense_score(q_out['dense_vecs'][0], doc_output['dense_vecs'][i])\n",
    "        s = sparse_score(q_out['lexical_weights'][0], doc_output['lexical_weights'][i])\n",
    "        c = colbert_score(q_out['colbert_vecs'][0], doc_output['colbert_vecs'][i])\n",
    "        all_scores.append((pid, text, d, s, c))\n",
    "    \n",
    "    # Normalize to [0, 1]\n",
    "    d_vals = [x[2] for x in all_scores]\n",
    "    s_vals = [x[3] for x in all_scores]\n",
    "    c_vals = [x[4] for x in all_scores]\n",
    "    \n",
    "    d_min, d_max = min(d_vals), max(d_vals)\n",
    "    s_min, s_max = min(s_vals), max(s_vals)\n",
    "    c_min, c_max = min(c_vals), max(c_vals)\n",
    "    \n",
    "    normalized = []\n",
    "    for pid, text, d, s, c in all_scores:\n",
    "        dn = (d - d_min) / (d_max - d_min) if d_max > d_min else 0.5\n",
    "        sn = (s - s_min) / (s_max - s_min) if s_max > s_min else 0.5\n",
    "        cn = (c - c_min) / (c_max - c_min) if c_max > c_min else 0.5\n",
    "        h = hybrid_score(dn, sn, cn)\n",
    "        normalized.append((pid, text, dn, sn, cn, h))\n",
    "    \n",
    "    # Sort by each mode\n",
    "    by_dense = sorted(normalized, key=lambda x: x[2], reverse=True)\n",
    "    by_sparse = sorted(normalized, key=lambda x: x[3], reverse=True)\n",
    "    by_colbert = sorted(normalized, key=lambda x: x[4], reverse=True)\n",
    "    by_hybrid = sorted(normalized, key=lambda x: x[5], reverse=True)\n",
    "    \n",
    "    # Find hybrid discoveries\n",
    "    top_d = set(x[0] for x in by_dense[:top_n])\n",
    "    top_s = set(x[0] for x in by_sparse[:top_n])\n",
    "    top_c = set(x[0] for x in by_colbert[:top_n])\n",
    "    \n",
    "    discoveries = []\n",
    "    for item in by_hybrid[:top_n]:\n",
    "        if item[0] not in top_d and item[0] not in top_s and item[0] not in top_c:\n",
    "            discoveries.append(item)\n",
    "    \n",
    "    return {\n",
    "        'dense': by_dense[:top_n],\n",
    "        'sparse': by_sparse[:top_n],\n",
    "        'colbert': by_colbert[:top_n],\n",
    "        'hybrid': by_hybrid[:top_n],\n",
    "        'discoveries': discoveries\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Primary example from blog post\nquery = \"spacious layout great for entertaining guests\"\nresults = rank_query(query, top_n=5)\n\nprint(f'Query: \"{query}\"\\n')\nprint(f\"Dense top 5:   {[x[0] for x in results['dense']]}\")\nprint(f\"Sparse top 5:  {[x[0] for x in results['sparse']]}\")\nprint(f\"ColBERT top 5: {[x[0] for x in results['colbert']]}\")\nprint(f\"Hybrid top 5:  {[x[0] for x in results['hybrid']]}\")\n\nif results['discoveries']:\n    print(f\"\\nHybrid discoveries (not in any mode's top 5): {len(results['discoveries'])}\")\n    for pid, text, dn, sn, cn, h in results['discoveries']:\n        print(f\"\\n  Property {pid}:\")\n        print(f\"    Dense={dn:.3f}, Sparse={sn:.3f}, ColBERT={cn:.3f}, Hybrid={h:.3f}\")\n        print(f\"    {text[:200]}...\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Testing Multiple Queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    \"quiet neighborhood with character and charm\",\n",
    "    \"spacious layout great for entertaining guests\",\n",
    "    \"well-maintained property in desirable location\",\n",
    "    \"modern downtown condo with parking\",\n",
    "    \"cozy home perfect for young family\",\n",
    "]\n",
    "\n",
    "for query in queries:\n",
    "    results = rank_query(query, top_n=5)\n",
    "    \n",
    "    if results['discoveries']:\n",
    "        print(f\"\\n{query}\")\n",
    "        print(f\"  Discoveries: {len(results['discoveries'])}\")\n",
    "        for pid, text, dn, sn, cn, h in results['discoveries']:\n",
    "            print(f\"    {pid}: hybrid={h:.3f} (d={dn:.3f}, s={sn:.3f}, c={cn:.3f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## When Hybrid Fails"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query where hybrid picks the wrong answer\n",
    "query = \"fixer-upper with potential good bones\"\n",
    "results = rank_query(query, top_n=3)\n",
    "\n",
    "print(f'Query: \"{query}\"\\n')\n",
    "print(\"Top 3 by hybrid:\")\n",
    "for pid, text, dn, sn, cn, h in results['hybrid']:\n",
    "    print(f\"\\n  {pid}: hybrid={h:.3f}\")\n",
    "    print(f\"    {text[:150]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}